
<!DOCTYPE html>
<html>
<head>
    <title>AI Voice Assistant</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 700px;
            width: 100%;
        }
        .status-section {
            text-align: center;
            margin-bottom: 30px;
        }
        .status-dot {
            width: 60px;
            height: 60px;
            border-radius: 50%;
            margin: 0 auto 20px;
            animation: pulse 2s infinite;
        }
        .status-dot.connecting { background: #ffc107; }
        .status-dot.connected { background: #28a745; }
        .status-dot.disconnected { background: #dc3545; animation: none; }
        .status-label {
            font-weight: 600;
            font-size: 24px;
            color: #333;
            margin-bottom: 10px;
        }
        .status-info {
            font-size: 14px;
            color: #666;
        }
        .notification {
            background: #4caf50;
            color: white;
            padding: 12px 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            text-align: center;
            font-size: 14px;
            font-weight: 500;
            display: none;
            animation: slideIn 0.3s ease;
        }
        .notification.show {
            display: block;
        }
        @keyframes slideIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .chat-section {
            margin-top: 20px;
        }
        .chat-box {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 15px;
            min-height: 100px;
            max-height: 200px;
            overflow-y: auto;
        }
        .chat-box h3 {
            font-size: 14px;
            text-transform: uppercase;
            letter-spacing: 1px;
            color: #667eea;
            margin-bottom: 10px;
        }
        .chat-content {
            font-size: 16px;
            color: #333;
            line-height: 1.6;
        }
        .user-transcript {
            background: #e3f2fd;
            padding: 10px 15px;
            border-radius: 8px;
            margin-bottom: 10px;
        }
        .ai-response {
            background: #f3e5f5;
            padding: 10px 15px;
            border-radius: 8px;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.7; transform: scale(1.1); }
        }
        .empty-state {
            color: #999;
            font-style: italic;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="status-section">
            <div class="status-dot" id="statusDot"></div>
            <div class="status-label" id="statusLabel">Connecting...</div>
            <div class="status-info" id="statusInfo">Loading...</div>
        </div>

        <div class="notification" id="notification">
            üîä Received audio from Deepgram
        </div>

        <div class="chat-section">
            <div class="chat-box">
                <h3>Your Transcript</h3>
                <div class="chat-content" id="transcriptContent">
                    <div class="empty-state">Speak to start...</div>
                </div>
            </div>

            <div class="chat-box">
                <h3>AI Response</h3>
                <div class="chat-content" id="responseContent">
                    <div class="empty-state">Waiting for response...</div>
                </div>
            </div>
        </div>
    </div>

    <script src="https://js.pusher.com/8.2.0/pusher.min.js"></script>
    <script>
        const params = new URLSearchParams(window.location.search);
        // const SERVER_URL = params.get('server') || 'https://zoom-bot-zkf2.vercel.app';
        const SERVER_URL = params.get('server') || 'https://zoom-bot-pgyj.onrender.com';
        // const SERVER_URL = params.get('server') || 'http://localhost:3000';
        const PUSHER_KEY = params.get('pusher_key') || '53efc497795d6002deb2';
        const PUSHER_CLUSTER = params.get('pusher_cluster') || 'ap2';
        
        const statusDot = document.getElementById('statusDot');
        const statusLabel = document.getElementById('statusLabel');
        const statusInfo = document.getElementById('statusInfo');
        const transcriptContent = document.getElementById('transcriptContent');
        const responseContent = document.getElementById('responseContent');
        const notification = document.getElementById('notification');
        const sessionId = 'session-' + Math.random().toString(36).substr(2, 9);

        console.log('üÜî Session ID:', sessionId);
        console.log('üåê Server:', SERVER_URL);

        function updateStatus(status, message) {
            statusDot.className = 'status-dot ' + status;
            statusLabel.textContent = message;
        }

        function showTranscript(text) {
            console.log('üìù Showing transcript:', text);
            transcriptContent.innerHTML = `<div class="user-transcript">${text}</div>`;
        }

        function showResponse(text) {
            console.log('ü§ñ Showing AI response:', text);
            responseContent.innerHTML = `<div class="ai-response">${text}</div>`;
        }

        function showNotification(message) {
            console.log('üîî Notification:', message);
            notification.textContent = message;
            notification.classList.add('show');
            setTimeout(() => {
                notification.classList.remove('show');
            }, 3000);
        }

        const audioCtx = new (window.AudioContext || window.webkitAudioContext)({ 
            sampleRate: 24000,
            latencyHint: 'interactive'
        });
        
        document.addEventListener('click', () => {
            if (audioCtx.state === 'suspended') {
                audioCtx.resume();
            }
        }, { once: true });

        function base64ToAudioBuffer(base64Audio) {
            const binaryString = atob(base64Audio);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            
            const int16Array = new Int16Array(bytes.buffer);
            const float32Array = new Float32Array(int16Array.length);
            const scale = 1 / 32768;
            
            for (let i = 0; i < int16Array.length; i++) {
                float32Array[i] = int16Array[i] * scale;
            }
            
            return float32Array;
        }

        async function playAudioImmediate(base64Audio, t0) {
            try {
                if (audioCtx.state === 'suspended') {
                    await audioCtx.resume();
                }
                
                const float32Array = base64ToAudioBuffer(base64Audio);
                const audioBuffer = audioCtx.createBuffer(1, float32Array.length, 24000);
                audioBuffer.getChannelData(0).set(float32Array);
                
                const source = audioCtx.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioCtx.destination);
                source.start(0);
                
                const t_play = Date.now();
                const y = t_play - t0;
                
                console.log(`[${y}ms] ‚ö° BROWSER STARTS PLAYING (T=Y)`);
                console.log(`‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n`);
                
            } catch (error) {
                console.error('PLAYBACK ERROR:', error);
            }
        }

        async function connectToServer() {
            try {
                updateStatus('connecting', 'Connecting...');
                
                // Initialize Pusher
                console.log('üì° Initializing Pusher...');
                const pusher = new Pusher(PUSHER_KEY, {
                    cluster: PUSHER_CLUSTER,
                    forceTLS: true
                });
                
                const channelName = `session-${sessionId}`;
                console.log('üì∫ Subscribing to channel:', channelName);
                const channel = pusher.subscribe(channelName);
                
                channel.bind('pusher:subscription_succeeded', () => {
                    console.log('‚úÖ Pusher subscription successful');
                });
                
           // Listen for interim transcripts (shows live updates)
channel.bind('transcript-interim', (data) => {
    console.log('üì• Received transcript-interim event:', data);
    if (data.text) {
        // Show interim in gray/italic style
        if (data.is_final && data.speech_final) {
            // Final transcript - bold style
            showTranscript(data.text);
        } else {
            // Interim transcript - show in lighter style
            transcriptContent.innerHTML = `<div class="user-transcript" style="opacity: 0.7; font-style: italic;">${data.text}</div>`;
        }
    }
});

// Listen for final transcript
channel.bind('transcript', (data) => {
    console.log('üì• Received final transcript event:', data);
    if (data.text) {
        showTranscript(data.text);
    }
});

// Listen for AI response
channel.bind('ai-response', (data) => {
    console.log('üì• Received AI response event:', data);
    if (data.text) {
        showResponse(data.text);
    }
});

// Listen for audio
channel.bind('audio-received', (data) => {
    console.log('üì• Received audio-received event:', data);
    showNotification('üîä Received audio from Deepgram');
});
                // Connect to backend
                const response = await fetch(`${SERVER_URL}/api/connect`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ sessionId })
                });
                
                if (!response.ok) throw new Error('Connection failed');
                
                console.log('‚úÖ Connected to server');
                updateStatus('connected', 'Ready');
                statusInfo.textContent = 'Speak now';
                
                // Poll for audio
                setInterval(async () => {
                    try {
                        const audioResponse = await fetch(`${SERVER_URL}/api/get-audio/${sessionId}`);
                        const data = await audioResponse.json();
                        
                        if (data.audio && data.audio.length > 0 && data.t0) {
                            for (const chunk of data.audio) {
                                await playAudioImmediate(chunk, data.t0);
                            }
                        }
                    } catch (error) {
                        // Silent
                    }
                }, 100);
                
                // Get microphone
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 24000,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                const captureContext = new AudioContext({ sampleRate: 24000 });
                const source = captureContext.createMediaStreamSource(stream);
                const processor = captureContext.createScriptProcessor(4096, 1, 1);
                
                processor.onaudioprocess = async (event) => {
                    const inputData = event.inputBuffer.getChannelData(0);
                    const int16Data = new Int16Array(inputData.length);
                    
                    for (let i = 0; i < inputData.length; i++) {
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }
                    
                    const uint8Data = new Uint8Array(int16Data.buffer);
                    let binary = '';
                    for (let i = 0; i < uint8Data.length; i++) {
                        binary += String.fromCharCode(uint8Data[i]);
                    }
                    const base64Audio = btoa(binary);
                    
                    try {
                        await fetch(`${SERVER_URL}/api/send-audio`, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({ sessionId, audio: base64Audio })
                        });
                    } catch (error) {
                        // Silent
                    }
                };
                
                source.connect(processor);
                processor.connect(captureContext.destination);
                
            } catch (error) {
                console.error('ERROR:', error);
                updateStatus('disconnected', 'Error');
                statusInfo.textContent = error.message;
            }
        }

        connectToServer();
    </script>
</body>
</html>
